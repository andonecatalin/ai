{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_date=\"2018-01-01\"\n",
    "end_date=\"2023-12-31\"\n",
    "tickers=[\"AAPL\",\"^GSPC\",\"MSFT\"]\n",
    "data1=yf.download('AAPL',start=start_date,end=end_date)\n",
    "data2=yf.download('^GSPC',start=start_date,end=end_date)\n",
    "data3=yf.download('MSFT',start=start_date,end=end_date)\n",
    "\n",
    "#for i in range(len(tickers)):\n",
    "#    df=pd.concat([df,yf.download(tickers[i],start=start_date,end=end_date)],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.rename(columns={'Open':'AAPL_Open'},inplace=True)\n",
    "data1.rename(columns={'High':'AAPL_High'},inplace=True)\n",
    "data1.rename(columns={'Low':'AAPL_Low'},inplace=True)\n",
    "data1.rename(columns={'Close':'AAPL_Close'},inplace=True)\n",
    "data1.rename(columns={'Adj Close':'AAPL_Adj Close'},inplace=True)\n",
    "data1.rename(columns={'Volume':'AAPL_Volume'},inplace=True)\n",
    "\n",
    "data2.rename(columns={'Open':'^GSPC_Open'},inplace=True)\n",
    "data2.rename(columns={'High':'^GSPC_High'},inplace=True)\n",
    "data2.rename(columns={'Low':'^GSPC_Low'},inplace=True)\n",
    "data2.rename(columns={'Close':'^GSPC_Close'},inplace=True)\n",
    "data2.rename(columns={'Adj Close':'^GSPC_Adj Close'},inplace=True)\n",
    "data2.rename(columns={'Volume':'^GSPC_Volume'},inplace=True)\n",
    "\n",
    "data3.rename(columns={'Open':'MSFT_Open'},inplace=True)\n",
    "data3.rename(columns={'High':'MSFT_High'},inplace=True)\n",
    "data3.rename(columns={'Low':'MSFT_Low'},inplace=True)\n",
    "data3.rename(columns={'Close':'MSFT_Close'},inplace=True)\n",
    "data3.rename(columns={'Adj Close':'MSFT_Adj Close'},inplace=True)\n",
    "data3.rename(columns={'Volume':'MSFT_Volume'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_Open</th>\n",
       "      <th>AAPL_High</th>\n",
       "      <th>AAPL_Low</th>\n",
       "      <th>AAPL_Close</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>AAPL_Volume</th>\n",
       "      <th>^GSPC_Open</th>\n",
       "      <th>^GSPC_High</th>\n",
       "      <th>^GSPC_Low</th>\n",
       "      <th>^GSPC_Close</th>\n",
       "      <th>^GSPC_Adj Close</th>\n",
       "      <th>^GSPC_Volume</th>\n",
       "      <th>MSFT_Open</th>\n",
       "      <th>MSFT_High</th>\n",
       "      <th>MSFT_Low</th>\n",
       "      <th>MSFT_Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MSFT_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>40.670975</td>\n",
       "      <td>102223600</td>\n",
       "      <td>2683.729980</td>\n",
       "      <td>2695.889893</td>\n",
       "      <td>2682.360107</td>\n",
       "      <td>2695.810059</td>\n",
       "      <td>2695.810059</td>\n",
       "      <td>3397430000</td>\n",
       "      <td>86.129997</td>\n",
       "      <td>86.309998</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>85.949997</td>\n",
       "      <td>80.080925</td>\n",
       "      <td>22483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>43.132500</td>\n",
       "      <td>43.637501</td>\n",
       "      <td>42.990002</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>40.663895</td>\n",
       "      <td>118071600</td>\n",
       "      <td>2697.850098</td>\n",
       "      <td>2714.370117</td>\n",
       "      <td>2697.770020</td>\n",
       "      <td>2713.060059</td>\n",
       "      <td>2713.060059</td>\n",
       "      <td>3544030000</td>\n",
       "      <td>86.059998</td>\n",
       "      <td>86.510002</td>\n",
       "      <td>85.970001</td>\n",
       "      <td>86.349998</td>\n",
       "      <td>80.453590</td>\n",
       "      <td>26061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>43.134998</td>\n",
       "      <td>43.367500</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>43.257500</td>\n",
       "      <td>40.852768</td>\n",
       "      <td>89738400</td>\n",
       "      <td>2719.310059</td>\n",
       "      <td>2729.290039</td>\n",
       "      <td>2719.070068</td>\n",
       "      <td>2723.989990</td>\n",
       "      <td>2723.989990</td>\n",
       "      <td>3697340000</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>87.660004</td>\n",
       "      <td>86.570000</td>\n",
       "      <td>87.110001</td>\n",
       "      <td>81.161697</td>\n",
       "      <td>21912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>43.360001</td>\n",
       "      <td>43.842499</td>\n",
       "      <td>43.262501</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>41.317909</td>\n",
       "      <td>94640000</td>\n",
       "      <td>2731.330078</td>\n",
       "      <td>2743.449951</td>\n",
       "      <td>2727.919922</td>\n",
       "      <td>2743.149902</td>\n",
       "      <td>2743.149902</td>\n",
       "      <td>3239280000</td>\n",
       "      <td>87.660004</td>\n",
       "      <td>88.410004</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>88.190002</td>\n",
       "      <td>82.167969</td>\n",
       "      <td>23407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>43.587502</td>\n",
       "      <td>43.902500</td>\n",
       "      <td>43.482498</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>41.164436</td>\n",
       "      <td>82271200</td>\n",
       "      <td>2742.669922</td>\n",
       "      <td>2748.510010</td>\n",
       "      <td>2737.600098</td>\n",
       "      <td>2747.709961</td>\n",
       "      <td>2747.709961</td>\n",
       "      <td>3246160000</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>88.580002</td>\n",
       "      <td>87.599998</td>\n",
       "      <td>88.279999</td>\n",
       "      <td>82.251816</td>\n",
       "      <td>22113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>195.179993</td>\n",
       "      <td>195.410004</td>\n",
       "      <td>192.970001</td>\n",
       "      <td>193.600006</td>\n",
       "      <td>193.353287</td>\n",
       "      <td>37122800</td>\n",
       "      <td>4753.919922</td>\n",
       "      <td>4772.939941</td>\n",
       "      <td>4736.770020</td>\n",
       "      <td>4754.629883</td>\n",
       "      <td>4754.629883</td>\n",
       "      <td>3046770000</td>\n",
       "      <td>373.679993</td>\n",
       "      <td>375.179993</td>\n",
       "      <td>372.709991</td>\n",
       "      <td>374.579987</td>\n",
       "      <td>373.888580</td>\n",
       "      <td>17091100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>193.610001</td>\n",
       "      <td>193.889999</td>\n",
       "      <td>192.830002</td>\n",
       "      <td>193.050003</td>\n",
       "      <td>192.803986</td>\n",
       "      <td>28919300</td>\n",
       "      <td>4758.859863</td>\n",
       "      <td>4784.720215</td>\n",
       "      <td>4758.450195</td>\n",
       "      <td>4774.750000</td>\n",
       "      <td>4774.750000</td>\n",
       "      <td>2513910000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>376.940002</td>\n",
       "      <td>373.500000</td>\n",
       "      <td>374.660004</td>\n",
       "      <td>373.968445</td>\n",
       "      <td>12673100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>192.490005</td>\n",
       "      <td>193.500000</td>\n",
       "      <td>191.089996</td>\n",
       "      <td>193.149994</td>\n",
       "      <td>192.903839</td>\n",
       "      <td>48087700</td>\n",
       "      <td>4773.450195</td>\n",
       "      <td>4785.390137</td>\n",
       "      <td>4768.899902</td>\n",
       "      <td>4781.580078</td>\n",
       "      <td>4781.580078</td>\n",
       "      <td>2748450000</td>\n",
       "      <td>373.690002</td>\n",
       "      <td>375.059998</td>\n",
       "      <td>372.809998</td>\n",
       "      <td>374.070007</td>\n",
       "      <td>373.379547</td>\n",
       "      <td>14905400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>194.139999</td>\n",
       "      <td>194.660004</td>\n",
       "      <td>193.169998</td>\n",
       "      <td>193.580002</td>\n",
       "      <td>193.333298</td>\n",
       "      <td>34049900</td>\n",
       "      <td>4786.439941</td>\n",
       "      <td>4793.299805</td>\n",
       "      <td>4780.979980</td>\n",
       "      <td>4783.350098</td>\n",
       "      <td>4783.350098</td>\n",
       "      <td>2698860000</td>\n",
       "      <td>375.369995</td>\n",
       "      <td>376.459991</td>\n",
       "      <td>374.160004</td>\n",
       "      <td>375.279999</td>\n",
       "      <td>374.587280</td>\n",
       "      <td>14327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>193.899994</td>\n",
       "      <td>194.399994</td>\n",
       "      <td>191.729996</td>\n",
       "      <td>192.529999</td>\n",
       "      <td>192.284637</td>\n",
       "      <td>42628800</td>\n",
       "      <td>4782.879883</td>\n",
       "      <td>4788.430176</td>\n",
       "      <td>4751.990234</td>\n",
       "      <td>4769.830078</td>\n",
       "      <td>4769.830078</td>\n",
       "      <td>3126060000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>377.160004</td>\n",
       "      <td>373.480011</td>\n",
       "      <td>376.040009</td>\n",
       "      <td>375.345886</td>\n",
       "      <td>18723000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1509 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAPL_Open   AAPL_High    AAPL_Low  AAPL_Close  AAPL_Adj Close  \\\n",
       "Date                                                                         \n",
       "2018-01-02   42.540001   43.075001   42.314999   43.064999       40.670975   \n",
       "2018-01-03   43.132500   43.637501   42.990002   43.057499       40.663895   \n",
       "2018-01-04   43.134998   43.367500   43.020000   43.257500       40.852768   \n",
       "2018-01-05   43.360001   43.842499   43.262501   43.750000       41.317909   \n",
       "2018-01-08   43.587502   43.902500   43.482498   43.587502       41.164436   \n",
       "...                ...         ...         ...         ...             ...   \n",
       "2023-12-22  195.179993  195.410004  192.970001  193.600006      193.353287   \n",
       "2023-12-26  193.610001  193.889999  192.830002  193.050003      192.803986   \n",
       "2023-12-27  192.490005  193.500000  191.089996  193.149994      192.903839   \n",
       "2023-12-28  194.139999  194.660004  193.169998  193.580002      193.333298   \n",
       "2023-12-29  193.899994  194.399994  191.729996  192.529999      192.284637   \n",
       "\n",
       "            AAPL_Volume   ^GSPC_Open   ^GSPC_High    ^GSPC_Low  ^GSPC_Close  \\\n",
       "Date                                                                          \n",
       "2018-01-02    102223600  2683.729980  2695.889893  2682.360107  2695.810059   \n",
       "2018-01-03    118071600  2697.850098  2714.370117  2697.770020  2713.060059   \n",
       "2018-01-04     89738400  2719.310059  2729.290039  2719.070068  2723.989990   \n",
       "2018-01-05     94640000  2731.330078  2743.449951  2727.919922  2743.149902   \n",
       "2018-01-08     82271200  2742.669922  2748.510010  2737.600098  2747.709961   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2023-12-22     37122800  4753.919922  4772.939941  4736.770020  4754.629883   \n",
       "2023-12-26     28919300  4758.859863  4784.720215  4758.450195  4774.750000   \n",
       "2023-12-27     48087700  4773.450195  4785.390137  4768.899902  4781.580078   \n",
       "2023-12-28     34049900  4786.439941  4793.299805  4780.979980  4783.350098   \n",
       "2023-12-29     42628800  4782.879883  4788.430176  4751.990234  4769.830078   \n",
       "\n",
       "            ^GSPC_Adj Close  ^GSPC_Volume   MSFT_Open   MSFT_High    MSFT_Low  \\\n",
       "Date                                                                            \n",
       "2018-01-02      2695.810059    3397430000   86.129997   86.309998   85.500000   \n",
       "2018-01-03      2713.060059    3544030000   86.059998   86.510002   85.970001   \n",
       "2018-01-04      2723.989990    3697340000   86.589996   87.660004   86.570000   \n",
       "2018-01-05      2743.149902    3239280000   87.660004   88.410004   87.430000   \n",
       "2018-01-08      2747.709961    3246160000   88.199997   88.580002   87.599998   \n",
       "...                     ...           ...         ...         ...         ...   \n",
       "2023-12-22      4754.629883    3046770000  373.679993  375.179993  372.709991   \n",
       "2023-12-26      4774.750000    2513910000  375.000000  376.940002  373.500000   \n",
       "2023-12-27      4781.580078    2748450000  373.690002  375.059998  372.809998   \n",
       "2023-12-28      4783.350098    2698860000  375.369995  376.459991  374.160004   \n",
       "2023-12-29      4769.830078    3126060000  376.000000  377.160004  373.480011   \n",
       "\n",
       "            MSFT_Close  MSFT_Adj Close  MSFT_Volume  \n",
       "Date                                                 \n",
       "2018-01-02   85.949997       80.080925     22483800  \n",
       "2018-01-03   86.349998       80.453590     26061400  \n",
       "2018-01-04   87.110001       81.161697     21912000  \n",
       "2018-01-05   88.190002       82.167969     23407100  \n",
       "2018-01-08   88.279999       82.251816     22113000  \n",
       "...                ...             ...          ...  \n",
       "2023-12-22  374.579987      373.888580     17091100  \n",
       "2023-12-26  374.660004      373.968445     12673100  \n",
       "2023-12-27  374.070007      373.379547     14905400  \n",
       "2023-12-28  375.279999      374.587280     14327000  \n",
       "2023-12-29  376.040009      375.345886     18723000  \n",
       "\n",
       "[1509 rows x 18 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.merge(data1,data2,on='Date',how='right')\n",
    "data=pd.merge(data,data3,on='Date',how='right')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI(nn.Module):\n",
    "    def __init__(self,nUnits,nLayers):\n",
    "        super().__init__()\n",
    "\n",
    "        # create dictionary to store the layers\n",
    "        self.layers = nn.ModuleDict()\n",
    "        self.nLayers = nLayers\n",
    "\n",
    "        ### input layer\n",
    "        self.layers['input'] = nn.Linear(18,nUnits)\n",
    "        \n",
    "        ### hidden layers\n",
    "        for i in range(nLayers):\n",
    "            self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
    "\n",
    "        ### output layer\n",
    "        self.layers['output'] = nn.Linear(nUnits,1)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.layers['input'](x))\n",
    "        for i in range(self.nLayers):\n",
    "            x=F.relu(self.layers[f'hidden{i}'](x))\n",
    "        x=self.layers['output'](x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AI(\n",
       "  (layers): ModuleDict(\n",
       "    (input): Linear(in_features=18, out_features=512, bias=True)\n",
       "    (hidden0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden5): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden7): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden8): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden9): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden10): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden11): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden12): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden13): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden14): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden15): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden16): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden17): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden18): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden19): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden20): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden21): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden22): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden23): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden24): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden25): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden26): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden27): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden28): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden29): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden30): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden31): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden32): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden33): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden34): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden35): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden36): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden37): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden38): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden39): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden40): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden41): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden42): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden43): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden44): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden45): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden46): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden47): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden48): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden49): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden50): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden51): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden52): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden53): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden54): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden55): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden56): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden57): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden58): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden59): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden60): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden61): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden62): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden63): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden64): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden65): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden66): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden67): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden68): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden69): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden70): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden71): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden72): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden73): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden74): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden75): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden76): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden77): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden78): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden79): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden80): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden81): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden82): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden83): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden84): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden85): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden86): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden87): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden88): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden89): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden90): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden91): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden92): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden93): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden94): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden95): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden96): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden97): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden98): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hidden99): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (output): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nUnitsPerLayer=512\n",
    "nLayers=100\n",
    "net=AI(nUnitsPerLayer,nLayers)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      " \n",
      "tensor([[0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078],\n",
      "        [0.0078]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tmpx=torch.randn(10,18)\n",
    "y=net(tmpx)\n",
    "print(y.shape),print(' ')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTheModel(theModel):\n",
    "    lossfun=nn.SmoothL1Loss()\n",
    "    optimizer=torch.optim.RMSprop(theModel.parameters(),lr=.01,momentum=.9)\n",
    "    for epochi in range(numepochs):\n",
    "        yHat=theModel(data)\n",
    "        loss=lossfun(yHat,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
