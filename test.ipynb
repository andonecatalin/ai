{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn as nn\n",
    "#import data_download\n",
    "import random\n",
    "import functions\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import polars as pl\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname='ai_dataset'\n",
    "dbuser='postgres'\n",
    "dbpassword='parola'\n",
    "dbport=5432\n",
    "dbhost='127.0.0.1'\n",
    "table_name='tabela'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[\"AAPL\",\"MSFT\",'SPY','XAUUSD.OANDA','BCO.ICMTRADER']\n",
    "for i in range(len(tickers)):\n",
    "    tickers[i]=tickers[i].replace('.','_')\n",
    "net_functions=functions.Protected_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_530, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>aapl_open</th><th>aapl_high</th><th>aapl_low</th><th>aapl_close</th><th>aapl_adj_close</th><th>aapl_volume</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2.585</td><td>2.6696</td><td>2.5804</td><td>2.2722</td><td>2.2722</td><td>8.0723443e8</td></tr><tr><td>2.6832</td><td>2.7136</td><td>2.6607</td><td>2.2789</td><td>2.2789</td><td>6.196036e8</td></tr><tr><td>2.6725</td><td>2.675</td><td>2.6339</td><td>2.2609</td><td>2.2609</td><td>4.494224e8</td></tr><tr><td>2.6875</td><td>2.7393</td><td>2.6625</td><td>2.3193</td><td>2.3193</td><td>7.044576e8</td></tr><tr><td>2.7404</td><td>2.7571</td><td>2.705</td><td>2.3118</td><td>2.3118</td><td>6.7504077e8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>195.18</td><td>195.41</td><td>192.97</td><td>193.6</td><td>193.6</td><td>3.71228e7</td></tr><tr><td>193.61</td><td>193.89</td><td>192.83</td><td>193.05</td><td>193.05</td><td>2.89193e7</td></tr><tr><td>192.49</td><td>193.5</td><td>191.09</td><td>193.15</td><td>193.15</td><td>4.80877e7</td></tr><tr><td>194.14</td><td>194.66</td><td>193.17</td><td>193.58</td><td>193.58</td><td>3.40499e7</td></tr><tr><td>193.9</td><td>194.4</td><td>191.73</td><td>192.53</td><td>192.53</td><td>4.26288e7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_530, 6)\n",
       "┌───────────┬───────────┬──────────┬────────────┬────────────────┬─────────────┐\n",
       "│ aapl_open ┆ aapl_high ┆ aapl_low ┆ aapl_close ┆ aapl_adj_close ┆ aapl_volume │\n",
       "│ ---       ┆ ---       ┆ ---      ┆ ---        ┆ ---            ┆ ---         │\n",
       "│ f64       ┆ f64       ┆ f64      ┆ f64        ┆ f64            ┆ f64         │\n",
       "╞═══════════╪═══════════╪══════════╪════════════╪════════════════╪═════════════╡\n",
       "│ 2.585     ┆ 2.6696    ┆ 2.5804   ┆ 2.2722     ┆ 2.2722         ┆ 8.0723443e8 │\n",
       "│ 2.6832    ┆ 2.7136    ┆ 2.6607   ┆ 2.2789     ┆ 2.2789         ┆ 6.196036e8  │\n",
       "│ 2.6725    ┆ 2.675     ┆ 2.6339   ┆ 2.2609     ┆ 2.2609         ┆ 4.494224e8  │\n",
       "│ 2.6875    ┆ 2.7393    ┆ 2.6625   ┆ 2.3193     ┆ 2.3193         ┆ 7.044576e8  │\n",
       "│ 2.7404    ┆ 2.7571    ┆ 2.705    ┆ 2.3118     ┆ 2.3118         ┆ 6.7504077e8 │\n",
       "│ …         ┆ …         ┆ …        ┆ …          ┆ …              ┆ …           │\n",
       "│ 195.18    ┆ 195.41    ┆ 192.97   ┆ 193.6      ┆ 193.6          ┆ 3.71228e7   │\n",
       "│ 193.61    ┆ 193.89    ┆ 192.83   ┆ 193.05     ┆ 193.05         ┆ 2.89193e7   │\n",
       "│ 192.49    ┆ 193.5     ┆ 191.09   ┆ 193.15     ┆ 193.15         ┆ 4.80877e7   │\n",
       "│ 194.14    ┆ 194.66    ┆ 193.17   ┆ 193.58     ┆ 193.58         ┆ 3.40499e7   │\n",
       "│ 193.9     ┆ 194.4     ┆ 191.73   ┆ 192.53     ┆ 192.53         ┆ 4.26288e7   │\n",
       "└───────────┴───────────┴──────────┴────────────┴────────────────┴─────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=net_functions.create_query(tickers[0],table_name)\n",
    "cursor,conn=net_functions.create_cursor(dbname,dbuser,dbpassword,dbport,dbhost)\n",
    "data=pl.read_database(query=query,connection=conn)\n",
    "#normalize with pandas\n",
    "\n",
    "data=data.drop_nulls()\n",
    "conn.close()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from polars\n",
    "#labels=data['labels']\n",
    "train_data=data['aapl_high']\n",
    "#make polars data into torch tensors\n",
    "train_data=torch.tensor(train_data)\n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten the tensor\n",
    "shortened_tensor=net_functions.tensor_shortner(train_data, batch_size)\n",
    "#create batches of 32\n",
    "image_tensor=net_functions.image_builder(shortened_tensor,batch_size=batch_size)\n",
    "#create tensor\n",
    "labels=net_functions.change(image_tensor, batch_size)\n",
    "\n",
    "#cut the last image from data variable to adjust for change function\n",
    "image_tensor=image_tensor[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make labels and data into tensors\n",
    "labels=torch.tensor(labels,dtype=torch.int32)\n",
    "image_tensor=torch.tensor(image_tensor)\n",
    "\n",
    "#move them to gpu\n",
    "labels=labels.to(device)\n",
    "image_tensor=image_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cpu = torch.tensor([1.0, 2.0, 3.0])\n",
    "tensor_cpu=tensor_cpu.to('cuda')\n",
    "tensor_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor(polars_fw,tensor, name, batch_size=32):\n",
    "    #make it compatible with the tickers list\n",
    "    name=name.lower()\n",
    "    replacement_map=[f'{name}_low',f'{name}_adj_close',f'{name}_volume']\n",
    "    for name in replacement_map:\n",
    "        #make it go trough all of the steps the original tensor goes\n",
    "        concat=polars[name]\n",
    "        concat=self.tensor_shortner(concat, batch_size)\n",
    "        concat=self.image_builder(concat, batch_size)\n",
    "        concat=concat[:-1]\n",
    "        concat=torch.tensor(concat)\n",
    "        if tensor.device==torch.device('cuda'):\n",
    "            concat=concat.to('cuda')\n",
    "        tensor=torch.cat((tensor, concat),dim=1)\n",
    "    return tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_functions.make_tensor(data,image_tensor,tickers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protected_execution:\n",
    "    def __init__(self):\n",
    "        self.garbage='nothing'\n",
    "    def create_query(name:str, table_name:str):\n",
    "        replacement_map=[f'{name}_Open',f'{name}_High',f'{name}_Low',f'{name}_Close',f'{name}_Adj_Close',f'{name}_Volume']\n",
    "        query=f\"SELECT {', '.join(replacement_map)} FROM {table_name} WHERE {replacement_map[0]} IS NOT NULL ORDER BY t ASC\"\n",
    "        return query\n",
    "\n",
    "    '''def request_data(self,name,table_name,dbname,dbuser,dbpassword,dbhost,dbport):\n",
    "        conn=psycopg2.connect(dbname=dbname,user=dbuser,password=dbpassword,host=dbhost,port=dbport)\n",
    "        cursor=conn.cursor()\n",
    "        query=self.create_query(name,table_name)\n",
    "        cursor.execute(query)\n",
    "        data=cursor.fetchall()\n",
    "        conn.close()\n",
    "\n",
    "        return data'''\n",
    "\n",
    "\n",
    "    '''def normal(arr):\n",
    "        \"\"\"\n",
    "        Normalizes a 1D NumPy array to a range between 0 and 1.\n",
    "\n",
    "        Args:\n",
    "            arr: A 1D NumPy array containing the data to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            A NumPy array containing the normalized data between 0 and 1.\n",
    "        \"\"\"\n",
    "        min_val = np.min(arr)\n",
    "        max_val = np.max(arr)\n",
    "        return (arr - min_val) / (max_val - min_val)'''\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    '''def ema(self,data:np.ndarray,perioada:int)->np.ndarray:\n",
    "        \"\"\"calculeaza Exponantial Moving aAverage\"\"\"\n",
    "        ema=[data[0]]\n",
    "        for i in range(1, len(data)):\n",
    "            weight=2.718/(perioada+1)\n",
    "            ema.append(data[i]*weight+ema[i-1]*(1-weight))\n",
    "        return np.array(ema,dtype=np.float64)'''\n",
    "    '''def macd(self,data:np.ndarray,fast_ema=12,slow_ema=26,signal_ema=7):\n",
    "        \"\"\"calculeaza Moving Avarege Convargence/Divergence\"\"\"\n",
    "        short_ema=self.ema(data,fast_ema)\n",
    "        long_ema=self.ema(data,slow_ema)\n",
    "        macd=short_ema-long_ema\n",
    "        signal=self.ema(macd,signal_ema)\n",
    "        return macd[-1]-signal[-1]'''\n",
    "    def insert_column(self,data,column_name,table_name,dbname,dbuser,dbpassword,dbhost,dbport):\n",
    "        conn=psycopg2.connect(dbname=dbname,user=dbuser,password=dbpassword,host=dbhost,port=dbport)\n",
    "        cursor=conn.cursor()\n",
    "        query=f\"\"\"\n",
    "            INSERT INTO {table_name} ({column_name})\n",
    "            VALUES({[number for number in data]})\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        conn.close()\n",
    "    def create_cursor(dbname,dbuser,dbpassword,dbport,dbhost):\n",
    "        conn=psycopg2.connect(dbname=dbname,user=dbuser,password=dbpassword,host=dbhost,port=dbport)\n",
    "        cursor=conn.cursor\n",
    "        return cursor,conn\n",
    "    def fit_to_range_tensor(data, min_value=-5, max_value=5):\n",
    "        \"\"\"\n",
    "        Fits a PyTorch tensor of numbers into a specified range.\n",
    "\n",
    "        Args:\n",
    "            data: The PyTorch tensor to fit.\n",
    "            min_value: The minimum value in the desired range (inclusive).\n",
    "            max_value: The maximum value in the desired range (inclusive).\n",
    "\n",
    "        Returns:\n",
    "            A new PyTorch tensor containing the fitted values.\n",
    "        \"\"\"\n",
    "        if not data.numel():\n",
    "            return torch.tensor([])  # Handle empty tensor\n",
    "\n",
    "        # Find minimum and maximum values in the tensor\n",
    "        data_min = torch.min(data)\n",
    "        data_max = torch.max(data)\n",
    "\n",
    "        # Handle constant data case (all elements have the same value)\n",
    "        if data_min == data_max:\n",
    "            return torch.full_like(data, min_value)\n",
    "\n",
    "        # Calculate scaling factor\n",
    "        scale = (max_value - min_value) / (data_max - data_min)\n",
    "\n",
    "        # Fit the tensor using broadcasting\n",
    "        fitted_data = min_value + scale * (data - data_min)\n",
    "\n",
    "        # Clip values to the range (optional)\n",
    "        clipped_data = torch.clamp(fitted_data, min_value, max_value)\n",
    "\n",
    "        return clipped_data\n",
    "    def tensor_shortner(tensor, requested_size):\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            tensor_size=tensor.size()[0]\n",
    "        elif isinstance(tensor, list):\n",
    "            tensor_size=len(tensor)\n",
    "        if tensor_size<requested_size:\n",
    "            raise Exception(\"Requested size is bigger or equal to tensor\")\n",
    "        \n",
    "        i=tensor_size\n",
    "        while i!=0:\n",
    "            if i % requested_size==0:\n",
    "                return tensor[:i]\n",
    "            i-=1\n",
    "    def image_builder(tensor:torch.Tensor, batch_size:int,shuffle=False):\n",
    "        #makes consecutive batches in form of a list\n",
    "        tensor_size=tensor.size()[0]\n",
    "        batches=[]\n",
    "        for i in range(tensor_size):\n",
    "            if i+batch_size<tensor_size-1:\n",
    "                batches.append([tensor[i:i+batch_size].tolist()])\n",
    "        if shuffle:\n",
    "            random.shuffle(batches)\n",
    "            \n",
    "        return batches\n",
    "\n",
    "    \n",
    "    def change(tensor:torch.Tensor, batch_size=32):\n",
    "        #shape from image_builder function goes like this:\n",
    "        #[batch number][leftover dimmension][element from batch]\n",
    "        empty_list=[]\n",
    "        for i in range(len(tensor)-1):\n",
    "            first=tensor[i+1][0][0]\n",
    "            last=tensor[i][0][batch_size-1]\n",
    "            diffrence=last-first\n",
    "            average=(last+first)/2\n",
    "            percent_diffrence=(diffrence/average)*100\n",
    "            #limits to 25 points +/- to make training achivable\n",
    "            #times 4 to increase sensitivity\n",
    "            if percent_diffrence >20:\n",
    "                percent_diffrence=20\n",
    "            elif percent_diffrence<-20:\n",
    "                percent_diffrence=-20\n",
    "            empty_list.append(round(percent_diffrence))\n",
    "        return empty_list        \n",
    "\n",
    "\n",
    "    def make_tensor(self,polars_fw,tensor, name, batch_size=32):\n",
    "        #make it compatible with the tickers list\n",
    "        self.name=name.lower()\n",
    "        self.replacement_map=[f'{self.name}_low',f'{self.name}_adj_close',f'{self.name}_volume']\n",
    "        for name in self.replacement_map:\n",
    "            #make it go trough all of the steps the original tensor goes\n",
    "            self.concat=polars_fw[name]\n",
    "            self.concat=self.tensor_shortner(self.concat, batch_size)\n",
    "            self.concat=image_builder(concat, batch_size)\n",
    "            self.concat=concat[:-1]\n",
    "            self.concat=torch.tensor(concat)\n",
    "            #move to the same device as original tensor\n",
    "            if tensor.device==torch.device('cuda'):\n",
    "                self.concat=self.concat.to('cuda')\n",
    "            #concatanate on dim=1\n",
    "            tensor=torch.cat((tensor, self.concat),dim=1)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obiect=Protected_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=net_functions.make_tensor(polars_fw=data, tensor=image_tensor, name=tickers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4478, 4, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6696e+00, 2.7136e+00, 2.6750e+00, 2.7393e+00, 2.7571e+00, 2.9246e+00,\n",
       "         3.0286e+00, 3.0857e+00, 3.0718e+00, 3.0850e+00, 3.0018e+00, 2.9164e+00,\n",
       "         2.8586e+00, 2.8414e+00, 2.8364e+00, 2.7679e+00, 2.6939e+00, 2.6286e+00,\n",
       "         2.7357e+00, 2.7264e+00, 2.7307e+00, 2.6914e+00, 2.5996e+00, 2.5896e+00,\n",
       "         2.4814e+00, 2.4671e+00, 2.4725e+00, 2.4168e+00, 2.3839e+00, 2.4321e+00,\n",
       "         2.4864e+00, 2.5361e+00],\n",
       "        [2.5804e+00, 2.6607e+00, 2.6339e+00, 2.6625e+00, 2.7050e+00, 2.7082e+00,\n",
       "         2.9496e+00, 2.9864e+00, 3.0214e+00, 2.9954e+00, 2.9232e+00, 2.8121e+00,\n",
       "         2.7082e+00, 2.7143e+00, 2.7061e+00, 2.6161e+00, 2.5689e+00, 2.5393e+00,\n",
       "         2.5311e+00, 2.6339e+00, 2.6657e+00, 2.5732e+00, 2.5371e+00, 2.3836e+00,\n",
       "         2.3814e+00, 2.3571e+00, 2.3046e+00, 2.2464e+00, 2.3086e+00, 2.3214e+00,\n",
       "         2.3839e+00, 2.4814e+00],\n",
       "        [2.2722e+00, 2.2789e+00, 2.2609e+00, 2.3193e+00, 2.3118e+00, 2.4580e+00,\n",
       "         2.5503e+00, 2.5622e+00, 2.6017e+00, 2.5750e+00, 2.5075e+00, 2.4027e+00,\n",
       "         2.3129e+00, 2.3609e+00, 2.3114e+00, 2.2555e+00, 2.1986e+00, 2.1895e+00,\n",
       "         2.2798e+00, 2.2953e+00, 2.2926e+00, 2.1917e+00, 2.1841e+00, 2.0458e+00,\n",
       "         2.0549e+00, 2.0917e+00, 1.9743e+00, 2.0460e+00, 1.9670e+00, 2.0561e+00,\n",
       "         2.1041e+00, 2.1452e+00],\n",
       "        [8.0723e+08, 6.1960e+08, 4.4942e+08, 7.0446e+08, 6.7504e+08, 2.2799e+09,\n",
       "         1.4938e+09, 1.2808e+09, 7.7631e+08, 8.3562e+08, 1.2006e+09, 1.6958e+09,\n",
       "         1.1348e+09, 1.0597e+09, 1.1423e+09, 1.2758e+09, 1.1814e+09, 9.5386e+08,\n",
       "         1.3984e+09, 9.1354e+08, 5.2119e+08, 7.0732e+08, 6.9212e+08, 1.6518e+09,\n",
       "         1.3888e+09, 9.5311e+08, 1.1498e+09, 1.7605e+09, 8.8350e+08, 1.1609e+09,\n",
       "         1.1598e+09, 9.4818e+08]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
