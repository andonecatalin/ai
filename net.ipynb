{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Execute once cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn as nn\n",
    "#import data_download\n",
    "import functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import polars as pl\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings for device\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception('Torch.cuda is not available')\n",
    "elif device!=torch.device('cuda'):\n",
    "    warnings.warn('Cuda is not selected as device even if it is available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname='ai_dataset'\n",
    "dbuser='postgres'\n",
    "dbpassword='parola'\n",
    "dbport=5432\n",
    "dbhost='127.0.0.1'\n",
    "table_name='tabela'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[\"AAPL\",\"MSFT\",'SPY','XAUUSD.OANDA','BCO.ICMTRADER']\n",
    "for i in range(len(tickers)):\n",
    "    tickers[i]=tickers[i].replace('.','_')\n",
    "net_functions=functions.Protected_execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_530, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>aapl_open</th><th>aapl_high</th><th>aapl_low</th><th>aapl_close</th><th>aapl_adj_close</th><th>aapl_volume</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2.585</td><td>2.6696</td><td>2.5804</td><td>2.2722</td><td>2.2722</td><td>8.0723443e8</td></tr><tr><td>2.6832</td><td>2.7136</td><td>2.6607</td><td>2.2789</td><td>2.2789</td><td>6.196036e8</td></tr><tr><td>2.6725</td><td>2.675</td><td>2.6339</td><td>2.2609</td><td>2.2609</td><td>4.494224e8</td></tr><tr><td>2.6875</td><td>2.7393</td><td>2.6625</td><td>2.3193</td><td>2.3193</td><td>7.044576e8</td></tr><tr><td>2.7404</td><td>2.7571</td><td>2.705</td><td>2.3118</td><td>2.3118</td><td>6.7504077e8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>195.18</td><td>195.41</td><td>192.97</td><td>193.6</td><td>193.6</td><td>3.71228e7</td></tr><tr><td>193.61</td><td>193.89</td><td>192.83</td><td>193.05</td><td>193.05</td><td>2.89193e7</td></tr><tr><td>192.49</td><td>193.5</td><td>191.09</td><td>193.15</td><td>193.15</td><td>4.80877e7</td></tr><tr><td>194.14</td><td>194.66</td><td>193.17</td><td>193.58</td><td>193.58</td><td>3.40499e7</td></tr><tr><td>193.9</td><td>194.4</td><td>191.73</td><td>192.53</td><td>192.53</td><td>4.26288e7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_530, 6)\n",
       "┌───────────┬───────────┬──────────┬────────────┬────────────────┬─────────────┐\n",
       "│ aapl_open ┆ aapl_high ┆ aapl_low ┆ aapl_close ┆ aapl_adj_close ┆ aapl_volume │\n",
       "│ ---       ┆ ---       ┆ ---      ┆ ---        ┆ ---            ┆ ---         │\n",
       "│ f64       ┆ f64       ┆ f64      ┆ f64        ┆ f64            ┆ f64         │\n",
       "╞═══════════╪═══════════╪══════════╪════════════╪════════════════╪═════════════╡\n",
       "│ 2.585     ┆ 2.6696    ┆ 2.5804   ┆ 2.2722     ┆ 2.2722         ┆ 8.0723443e8 │\n",
       "│ 2.6832    ┆ 2.7136    ┆ 2.6607   ┆ 2.2789     ┆ 2.2789         ┆ 6.196036e8  │\n",
       "│ 2.6725    ┆ 2.675     ┆ 2.6339   ┆ 2.2609     ┆ 2.2609         ┆ 4.494224e8  │\n",
       "│ 2.6875    ┆ 2.7393    ┆ 2.6625   ┆ 2.3193     ┆ 2.3193         ┆ 7.044576e8  │\n",
       "│ 2.7404    ┆ 2.7571    ┆ 2.705    ┆ 2.3118     ┆ 2.3118         ┆ 6.7504077e8 │\n",
       "│ …         ┆ …         ┆ …        ┆ …          ┆ …              ┆ …           │\n",
       "│ 195.18    ┆ 195.41    ┆ 192.97   ┆ 193.6      ┆ 193.6          ┆ 3.71228e7   │\n",
       "│ 193.61    ┆ 193.89    ┆ 192.83   ┆ 193.05     ┆ 193.05         ┆ 2.89193e7   │\n",
       "│ 192.49    ┆ 193.5     ┆ 191.09   ┆ 193.15     ┆ 193.15         ┆ 4.80877e7   │\n",
       "│ 194.14    ┆ 194.66    ┆ 193.17   ┆ 193.58     ┆ 193.58         ┆ 3.40499e7   │\n",
       "│ 193.9     ┆ 194.4     ┆ 191.73   ┆ 192.53     ┆ 192.53         ┆ 4.26288e7   │\n",
       "└───────────┴───────────┴──────────┴────────────┴────────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=net_functions.create_query(tickers[0],table_name)\n",
    "cursor,conn=net_functions.create_cursor(dbname,dbuser,dbpassword,dbport,dbhost)\n",
    "data=pl.read_database(query=query,connection=conn)\n",
    "#data=data.with_columns(pl.col('aapl_adj_close').pct_change().alias('labels'))\n",
    "#normalize with pandas\n",
    "#data= data.select((pl.all()-pl.all().mean()) / pl.all().std())\n",
    "\n",
    "data=data.drop_nulls()\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from polars\n",
    "#labels=data['labels']\n",
    "train_data=data['aapl_high']\n",
    "#make polars data into torch tensors\n",
    "train_data=torch.tensor(train_data)\n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten the tensor\n",
    "shortened_tensor=net_functions.tensor_shortner(train_data, batch_size)\n",
    "#create batches of 32\n",
    "image_tensor=net_functions.image_builder(shortened_tensor,batch_size=batch_size)\n",
    "#create tensor\n",
    "labels=net_functions.change(image_tensor, batch_size)\n",
    "#cut the last image from data variable to adjust for change function\n",
    "image_tensor=image_tensor[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[x+20 for x in labels]\n",
    "max(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make labels and data into tensors\n",
    "labels=torch.tensor(labels,dtype=torch.int32)\n",
    "\n",
    "labels=labels.type(torch.LongTensor)\n",
    "image_tensor=torch.tensor(image_tensor)\n",
    "\n",
    "image_tensor=net_functions.make_tensor(data,image_tensor,tickers[0])\n",
    "\n",
    "\n",
    "#normalize data tensor\n",
    "#image_tensor=net_functions.fit_to_range_tensor(image_tensor)\n",
    "\n",
    "\n",
    "#move them to gpu\n",
    "labels=labels.to(device)\n",
    "image_tensor=image_tensor.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4478, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "def min_max_normalize(tensor):\n",
    "    for c in range(tensor.size(1)):\n",
    "        channel_min = tensor[:, c, :].min()\n",
    "        channel_max = tensor[:, c, :].max()\n",
    "        tensor[:, c, :] = (tensor[:, c, :] - channel_min) / (channel_max - channel_min)\n",
    "    return tensor\n",
    "\n",
    "print(image_tensor.shape)\n",
    "image_tensor = min_max_normalize(image_tensor)  # Use clone() to avoid modifying the original tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data with sklearn\n",
    "train_dataset,test_dataset,train_labels,test_labels=train_test_split(image_tensor,labels,test_size=.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1):\n",
    "        self.T_0 = T_0\n",
    "        self.T_cur = 0\n",
    "        self.T_mult = T_mult\n",
    "        self.eta_min = eta_min\n",
    "        super(SGDRScheduler, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == 0:\n",
    "            self.T_i = self.T_0\n",
    "        else:\n",
    "            self.T_i = self.T_0 * (self.T_mult ** (self.last_epoch // self.T_0))\n",
    "        \n",
    "        cos_inner = np.pi * (self.T_cur % self.T_i)\n",
    "        cos_inner /= self.T_i\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        return [self.eta_min + (base_lr - self.eta_min) / 2 * cos_out for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, epoch=None):\n",
    "        if epoch is not None:\n",
    "            self.T_cur = epoch % self.T_i\n",
    "        super(SGDRScheduler, self).step(epoch)\n",
    "        if epoch is not None and epoch % self.T_i == 0:\n",
    "            self.T_cur = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def createTheMNISTNet(printtoggle=False):\n",
    "\n",
    "  class mnistNet(nn.Module):\n",
    "    def __init__(self, printtoggle=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input layer for 1D data of size 32\n",
    "        self.conv1a = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=1, stride=1, padding=2)\n",
    "        self.conv2a = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=1, stride=1, padding=2)\n",
    "\n",
    "        self.conv1b = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=2, stride=1, padding=2)\n",
    "        self.conv2b = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=2, stride=1, padding=2)\n",
    "\n",
    "        self.conv1c = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2c = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, stride=1, padding=2)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv2d = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=4, stride=1, padding=2)\n",
    "\n",
    "        self.conv1e = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2e = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.conv1f = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=6, stride=1, padding=2)\n",
    "        self.conv2f = nn.Conv1d(in_channels=4, out_channels=4, kernel_size=6, stride=1, padding=2)\n",
    "        \n",
    "        self.pool=nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        # fully-connected layers\n",
    "        self.fc1 = nn.Linear(832, 416) \n",
    "        self.fc2 = nn.Linear(416, 208)\n",
    "        #self.fc3 = nn.Linear(416, 208)\n",
    "        self.fc4 = nn.Linear(208, 128)  # Assuming 10 output classes\n",
    "        self.fc5 = nn.Linear(128, 41)  # Assuming 10 output classes\n",
    "\n",
    "        # toggle for printing out tensor sizes during forward prop\n",
    "        #self.print = printtoggle\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        # Use GPU if available\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.to(self.device)  # Move the model to the chosen device\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, x):\n",
    "        # Move input to device\n",
    "        #x = x.to(self.device)\n",
    "        x_context=x[0]\n",
    "        x_a=x\n",
    "        x_b=x\n",
    "        x_c=x\n",
    "        x_d=x\n",
    "        x_e=x\n",
    "        x_f=x\n",
    "        \n",
    "        #print(f' inainte de conv: {x.shape}')\n",
    "\n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_a = F.relu(self.conv1a(x))\n",
    "        x_a = self.pool(x)\n",
    "        x_a = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_a = F.relu(self.conv2a(x))\n",
    "        x_a = self.pool(x)\n",
    "        x_a = self.dropout(x)\n",
    "        '''####################################################'''\n",
    "\n",
    "        \n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_b = F.relu(self.conv1b(x))\n",
    "        x_b = self.pool(x)\n",
    "        x_b = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_b = F.relu(self.conv2b(x))\n",
    "        x_b = self.pool(x)\n",
    "        x_b = self.dropout(x)\n",
    "\n",
    "\n",
    "        \n",
    "        '''####################################################'''\n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_c = F.relu(self.conv1c(x))\n",
    "        x_c = self.pool(x)\n",
    "        x_c = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_c = F.relu(self.conv2c(x))\n",
    "        x_c = self.pool(x)\n",
    "        x_c = self.dropout(x)\n",
    "\n",
    "\n",
    "        \n",
    "        '''####################################################'''\n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_d = F.relu(self.conv1d(x))\n",
    "        x_d = self.pool(x)\n",
    "        x_d = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_d = F.relu(self.conv2d(x))\n",
    "        x_d = self.pool(x)\n",
    "        x_d = self.dropout(x)\n",
    "\n",
    "\n",
    "        \n",
    "        '''####################################################'''\n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_e = F.relu(self.conv1e(x))\n",
    "        x_e = self.pool(x)\n",
    "        x_e = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_e = F.relu(self.conv2e(x))\n",
    "        x_e = self.pool(x)\n",
    "        x_e = self.dropout(x)\n",
    "\n",
    "\n",
    "        \n",
    "        '''####################################################'''\n",
    "        #next window\n",
    "        # Convolution -> relu\n",
    "        x_f = F.relu(self.conv1f(x))\n",
    "        x_f = self.pool(x)\n",
    "        x_f = self.dropout(x)\n",
    "        \n",
    "        # Convolution -> relu\n",
    "        x_f = F.relu(self.conv2f(x))\n",
    "        x_f = self.pool(x)\n",
    "        x_f = self.dropout(x)\n",
    "\n",
    "\n",
    "        \n",
    "        '''####################################################'''\n",
    "        x=torch.cat([x_a,x_b,x_c,x_d,x_e,x_f],0)\n",
    "        x = x.view(-1)  # Flatten the tensor\n",
    "        x = torch.cat([x_context,x])\n",
    "        # Fully connected layer\n",
    "\n",
    "        \n",
    "        x=torch.cat([x_context,x])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # create the model instance\n",
    "  net = mnistNet(printtoggle)\n",
    "  \n",
    "  # loss function (assuming classification task)\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = optim.SGD(net.parameters(),lr=.01)\n",
    "  T_0=40\n",
    "  scheduler=SGDRScheduler(optimizer, T_0=T_0,T_mult=2,eta_min=0.005)  \n",
    "\n",
    "  return net,lossfun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(train_dataset, train_labels, test_dataset, test_labels,numepochs = 50):\n",
    "\n",
    "  # number of epochs\n",
    "  \n",
    "  \n",
    "  # create a new model\n",
    "  net, lossfun, optimizer = createTheMNISTNet()\n",
    "\n",
    "  # initialize losses\n",
    "  losses = torch.zeros(numepochs).to(device)\n",
    "  trainAcc = []\n",
    "  testAcc = []\n",
    "  z=0\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "    z+=1\n",
    "    # initialize batch losses and accuracies\n",
    "    epochLoss = 0.0\n",
    "    epochAcc = 0.0\n",
    "    print(z)\n",
    "    # loop over training data batches\n",
    "    for i in range(train_dataset.size()[0]):\n",
    "      X=train_dataset[i]\n",
    "      y=train_labels[i]\n",
    "      \n",
    "      #X = X.unsqueeze(1)  # Add a singleton dimension for the channel axis\n",
    "     \n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "        \n",
    "      loss = lossfun(yHat, y)\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # accumulate batch loss\n",
    "      epochLoss += loss.item()\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat, axis=0) == y\n",
    "      accuracyPct = 100 * torch.mean(matches.float())\n",
    "      epochAcc += accuracyPct.item()\n",
    "\n",
    "    # end of batch loop\n",
    "\n",
    "    # average loss and accuracy for the epoch\n",
    "    epochLoss /= train_dataset.size()[0]\n",
    "    epochAcc /= train_dataset.size()[0]\n",
    "\n",
    "    # append to lists\n",
    "    losses[epochi] = epochLoss\n",
    "    trainAcc.append(epochAcc)\n",
    "\n",
    "    # test accuracy (evaluate on test set)\n",
    "    test_epochAcc = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    '''with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)  # Move data to device\n",
    "            yHat_test = net(X_test)\n",
    "            matches_test = torch.argmax(yHat_test, dim=1) == y_test\n",
    "            total_correct += matches_test.sum().item()\n",
    "            total_samples += y_test.size(0)\n",
    "    \n",
    "    test_epochAcc = 100 * total_correct / total_samples\n",
    "    testAcc.append(test_epochAcc)\n",
    "\n",
    "     ''' \n",
    "    test_epochAcc = 0.0\n",
    "    with torch.no_grad():\n",
    "      for i_test in range(test_dataset.size()[0]):\n",
    "        X_test=test_dataset[i_test]\n",
    "        y_test=test_labels[i_test]\n",
    "        yHat_test=net(X_test)\n",
    "        matches_test = torch.argmax(yHat_test, axis=0) == y_test\n",
    "        accuracyPct_test = 100 * torch.mean(matches_test.float())\n",
    "        test_epochAcc += accuracyPct_test.item()\n",
    "    test_epochAcc /= train_dataset.size()[0]\n",
    "    testAcc.append(test_epochAcc)\n",
    "\n",
    "  # end epochs loop\n",
    "\n",
    "  # function output\n",
    "  return trainAcc, testAcc, losses, net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainAcc,testAcc,losses,net = function2trainTheModel(train_dataset, train_labels, test_dataset, test_labels,numepochs = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5707196029776674,\n",
       " 0.6451612903225806,\n",
       " 0.7444168734491315,\n",
       " 0.7444168734491315,\n",
       " 0.7196029776674938,\n",
       " 0.794044665012407,\n",
       " 0.794044665012407,\n",
       " 0.794044665012407,\n",
       " 0.8436724565756824,\n",
       " 0.8933002481389578,\n",
       " 1.066997518610422,\n",
       " 0.794044665012407,\n",
       " 1.1910669975186103,\n",
       " 1.0173697270471465,\n",
       " 1.0918114143920596,\n",
       " 0.9925558312655087,\n",
       " 1.066997518610422,\n",
       " 0.9181141439205955,\n",
       " 1.0173697270471465,\n",
       " 0.8933002481389578,\n",
       " 0.9925558312655087,\n",
       " 1.1166253101736974,\n",
       " 1.2655086848635235,\n",
       " 1.2406947890818858,\n",
       " 0.9181141439205955,\n",
       " 0.8933002481389578,\n",
       " 1.0421836228287842,\n",
       " 1.3399503722084367,\n",
       " 0.967741935483871,\n",
       " 1.1414392059553349,\n",
       " 1.1166253101736974,\n",
       " 1.1414392059553349,\n",
       " 1.215880893300248,\n",
       " 1.2406947890818858,\n",
       " 1.1910669975186103,\n",
       " 1.2655086848635235,\n",
       " 1.1662531017369726,\n",
       " 1.2655086848635235,\n",
       " 1.3647642679900744,\n",
       " 1.1662531017369726,\n",
       " 0.967741935483871,\n",
       " 1.2406947890818858,\n",
       " 1.2655086848635235,\n",
       " 1.2903225806451613,\n",
       " 1.215880893300248,\n",
       " 1.3399503722084367,\n",
       " 1.1910669975186103,\n",
       " 1.0918114143920596,\n",
       " 1.066997518610422,\n",
       " 1.1662531017369726,\n",
       " 1.3399503722084367,\n",
       " 1.1910669975186103,\n",
       " 1.1166253101736974,\n",
       " 1.1414392059553349,\n",
       " 1.0173697270471465,\n",
       " 1.41439205955335,\n",
       " 1.0918114143920596,\n",
       " 1.315136476426799,\n",
       " 1.2655086848635235,\n",
       " 1.215880893300248,\n",
       " 1.1166253101736974,\n",
       " 1.215880893300248,\n",
       " 1.1910669975186103,\n",
       " 1.1662531017369726,\n",
       " 1.2655086848635235,\n",
       " 1.1414392059553349,\n",
       " 1.3647642679900744,\n",
       " 0.9925558312655087,\n",
       " 1.1166253101736974,\n",
       " 1.066997518610422,\n",
       " 1.2655086848635235,\n",
       " 1.0918114143920596,\n",
       " 1.1414392059553349,\n",
       " 1.0918114143920596,\n",
       " 1.1166253101736974,\n",
       " 1.1414392059553349,\n",
       " 1.1910669975186103,\n",
       " 1.2655086848635235,\n",
       " 1.2903225806451613,\n",
       " 1.2406947890818858,\n",
       " 1.0918114143920596,\n",
       " 1.315136476426799,\n",
       " 1.1662531017369726,\n",
       " 1.1662531017369726,\n",
       " 1.3399503722084367,\n",
       " 1.1414392059553349,\n",
       " 0.9925558312655087,\n",
       " 1.0918114143920596,\n",
       " 1.1166253101736974,\n",
       " 1.1414392059553349,\n",
       " 1.1414392059553349,\n",
       " 1.3399503722084367,\n",
       " 1.215880893300248,\n",
       " 1.215880893300248,\n",
       " 1.1166253101736974,\n",
       " 1.3399503722084367,\n",
       " 1.3647642679900744,\n",
       " 1.1414392059553349,\n",
       " 1.1662531017369726,\n",
       " 1.2903225806451613,\n",
       " 1.3895781637717122,\n",
       " 1.0918114143920596,\n",
       " 1.588089330024814,\n",
       " 1.5136476426799008,\n",
       " 1.2903225806451613,\n",
       " 1.2406947890818858,\n",
       " 1.066997518610422,\n",
       " 1.2406947890818858,\n",
       " 1.1414392059553349,\n",
       " 1.1662531017369726,\n",
       " 1.3647642679900744,\n",
       " 1.2406947890818858,\n",
       " 1.1414392059553349,\n",
       " 1.2406947890818858,\n",
       " 1.1166253101736974,\n",
       " 1.3399503722084367,\n",
       " 1.215880893300248,\n",
       " 1.3895781637717122,\n",
       " 1.3647642679900744,\n",
       " 1.2655086848635235,\n",
       " 1.215880893300248,\n",
       " 1.2655086848635235,\n",
       " 1.5136476426799008,\n",
       " 1.2406947890818858,\n",
       " 1.3647642679900744,\n",
       " 1.3399503722084367,\n",
       " 1.3647642679900744,\n",
       " 1.1910669975186103,\n",
       " 1.4392059553349876,\n",
       " 1.3399503722084367,\n",
       " 1.1910669975186103,\n",
       " 1.066997518610422,\n",
       " 1.315136476426799,\n",
       " 1.2903225806451613,\n",
       " 1.1910669975186103,\n",
       " 1.2655086848635235,\n",
       " 1.1414392059553349,\n",
       " 1.215880893300248,\n",
       " 1.2903225806451613,\n",
       " 1.4392059553349876,\n",
       " 1.315136476426799,\n",
       " 1.4392059553349876,\n",
       " 1.488833746898263,\n",
       " 1.3647642679900744,\n",
       " 1.2903225806451613,\n",
       " 1.0918114143920596,\n",
       " 1.066997518610422,\n",
       " 1.3895781637717122,\n",
       " 1.2903225806451613,\n",
       " 1.315136476426799,\n",
       " 1.2655086848635235,\n",
       " 1.1910669975186103,\n",
       " 1.41439205955335,\n",
       " 1.3895781637717122,\n",
       " 1.0421836228287842,\n",
       " 1.2406947890818858,\n",
       " 1.1166253101736974,\n",
       " 1.1910669975186103,\n",
       " 1.4640198511166254,\n",
       " 1.2903225806451613,\n",
       " 1.5384615384615385,\n",
       " 0.9925558312655087,\n",
       " 1.2903225806451613,\n",
       " 1.3895781637717122,\n",
       " 1.215880893300248,\n",
       " 1.3647642679900744,\n",
       " 1.4640198511166254,\n",
       " 1.2655086848635235,\n",
       " 1.3399503722084367,\n",
       " 1.3399503722084367,\n",
       " 1.1414392059553349,\n",
       " 1.2406947890818858,\n",
       " 1.1662531017369726,\n",
       " 1.41439205955335,\n",
       " 1.41439205955335,\n",
       " 1.2903225806451613,\n",
       " 1.4640198511166254,\n",
       " 1.1414392059553349,\n",
       " 1.3647642679900744,\n",
       " 1.3399503722084367,\n",
       " 1.488833746898263,\n",
       " 1.3399503722084367,\n",
       " 1.1910669975186103,\n",
       " 1.3895781637717122,\n",
       " 1.1910669975186103,\n",
       " 1.2655086848635235,\n",
       " 1.3647642679900744,\n",
       " 1.3399503722084367,\n",
       " 1.2903225806451613,\n",
       " 1.1910669975186103,\n",
       " 1.2903225806451613,\n",
       " 1.4392059553349876,\n",
       " 1.3647642679900744,\n",
       " 1.2903225806451613,\n",
       " 1.4640198511166254,\n",
       " 1.41439205955335,\n",
       " 1.066997518610422,\n",
       " 1.0421836228287842,\n",
       " 1.4392059553349876,\n",
       " 1.1414392059553349,\n",
       " 1.4392059553349876,\n",
       " 1.315136476426799,\n",
       " 1.41439205955335,\n",
       " 1.3399503722084367,\n",
       " 1.3399503722084367,\n",
       " 1.1166253101736974,\n",
       " 1.2406947890818858,\n",
       " 1.2655086848635235,\n",
       " 1.315136476426799,\n",
       " 1.2903225806451613,\n",
       " 1.315136476426799,\n",
       " 1.2903225806451613,\n",
       " 1.488833746898263,\n",
       " 1.41439205955335,\n",
       " 1.3895781637717122,\n",
       " 1.1662531017369726,\n",
       " 1.3895781637717122,\n",
       " 1.3647642679900744,\n",
       " 1.215880893300248,\n",
       " 1.315136476426799,\n",
       " 1.3399503722084367,\n",
       " 1.2903225806451613,\n",
       " 1.1166253101736974,\n",
       " 1.3647642679900744,\n",
       " 1.5632754342431763,\n",
       " 1.3399503722084367,\n",
       " 1.488833746898263,\n",
       " 1.2655086848635235,\n",
       " 1.3895781637717122,\n",
       " 1.662531017369727,\n",
       " 1.5384615384615385,\n",
       " 1.3647642679900744,\n",
       " 1.1166253101736974,\n",
       " 1.215880893300248,\n",
       " 1.3647642679900744,\n",
       " 1.1414392059553349,\n",
       " 1.41439205955335,\n",
       " 1.41439205955335,\n",
       " 1.3647642679900744,\n",
       " 1.315136476426799,\n",
       " 1.315136476426799,\n",
       " 1.1910669975186103,\n",
       " 1.2655086848635235,\n",
       " 1.1662531017369726,\n",
       " 1.1910669975186103,\n",
       " 1.215880893300248,\n",
       " 1.5384615384615385,\n",
       " 1.1910669975186103,\n",
       " 1.488833746898263,\n",
       " 1.2655086848635235,\n",
       " 1.1910669975186103,\n",
       " 1.315136476426799,\n",
       " 1.1662531017369726,\n",
       " 1.2406947890818858,\n",
       " 1.5384615384615385,\n",
       " 1.1662531017369726,\n",
       " 1.2406947890818858,\n",
       " 1.2406947890818858,\n",
       " 1.3399503722084367,\n",
       " 1.066997518610422,\n",
       " 1.3895781637717122,\n",
       " 1.3895781637717122,\n",
       " 1.1910669975186103,\n",
       " 1.2903225806451613,\n",
       " 1.488833746898263,\n",
       " 1.2903225806451613,\n",
       " 1.315136476426799,\n",
       " 1.2903225806451613,\n",
       " 1.4392059553349876,\n",
       " 1.3895781637717122,\n",
       " 1.41439205955335,\n",
       " 1.3895781637717122,\n",
       " 1.2406947890818858,\n",
       " 1.5136476426799008,\n",
       " 1.4392059553349876,\n",
       " 1.1662531017369726,\n",
       " 1.4392059553349876,\n",
       " 1.1414392059553349,\n",
       " 1.1910669975186103,\n",
       " 1.4640198511166254,\n",
       " 1.3399503722084367,\n",
       " 1.4392059553349876,\n",
       " 1.1910669975186103,\n",
       " 1.3399503722084367,\n",
       " 1.3647642679900744,\n",
       " 1.7369727047146402,\n",
       " 1.215880893300248,\n",
       " 1.0918114143920596,\n",
       " 1.488833746898263,\n",
       " 1.3399503722084367,\n",
       " 1.2903225806451613,\n",
       " 1.2655086848635235,\n",
       " 1.5384615384615385,\n",
       " 1.2903225806451613,\n",
       " 1.1414392059553349,\n",
       " 1.3647642679900744,\n",
       " 1.2406947890818858,\n",
       " 1.1662531017369726,\n",
       " 1.41439205955335,\n",
       " 1.315136476426799]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'losses over time')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nploss=losses.to(\"cpu\")\n",
    "nploss=nploss.cpu()\n",
    "losses=losses.cpu().numpy()\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.title('losses over time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_dataset, test_labels, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for i_test in range(test_dataset.size()[0]):\n",
    "        X_test=test_dataset[i_test]\n",
    "        y_test=test_labels[i_test]\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        X_test=X_test.unsqueeze(1)\n",
    "        output = model(X_test)\n",
    "        test_loss += criterion(output, y_test).item()  # Sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataset)\n",
    "    accuracy = 100. * correct / len(test_dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataset)} '\n",
    "          f'({accuracy:.0f}%)\\n')\n",
    "    print(nploss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [4, 4, 1], expected input[4, 1, 32] to have 4 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_dataset, test_labels, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mto(device), y_test\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m X_test\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, y_test)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Sum up batch loss\u001b[39;00m\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Get the index of the max log-probability\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 57\u001b[0m, in \u001b[0;36mcreateTheMNISTNet.<locals>.mnistNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m x_f\u001b[38;5;241m=\u001b[39mx\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#print(f' inainte de conv: {x.shape}')\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#next window\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Convolution -> relu\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m x_a \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     58\u001b[0m x_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m     59\u001b[0m x_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [4, 4, 1], expected input[4, 1, 32] to have 4 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "test(net,device,test_dataset, test_labels,nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
